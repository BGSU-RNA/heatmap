#!/usr/bin/env python

import os
import re
import csv
import sys
import json
import shutil

import itertools as it

from sqlalchemy import Table
from sqlalchemy import MetaData
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

IMAGE_URL = 'static/img/{0}/{0}_{1}_exemplar.png'
FRAGMENT_URL = 'static/data/{0}/{1}-{2}.pdb'


with open('config.json', 'r') as raw:
    config = json.load(raw)
    engine = create_engine(config['db'])
    DB = sessionmaker(bind=engine)
    meta = MetaData()
    MappingTable = Table('pdb_unit_id_correspondence', meta, autoload=True,
                         autoload_with=engine)


def convert_ids(ids):
    ids = [id for id in ids if id]
    if not ids:
        return []
    session = DB()
    query = session.query(MappingTable.c.unit_id, MappingTable.c.old_id).\
        filter(MappingTable.c.old_id.in_(ids))
    results = {result[1]: result[0] for result in query}
    if len(results) != len(ids):
        sys.stderr.write("Can't find all ids: %s\n" % ",".join(ids))
        sys.exit(1)
    return [results[id] for id in ids]


def generate_data(header, rows):
    data = {'items': {}, 'pairs': [], 'files': {}}

    names = map(lambda r: r[1], rows)

    for row in it.imap(lambda r: dict(it.izip(header, r)), rows):
        first = row['Base combination']
        family = row['Family']
        known = True
        units = convert_ids([row['NT1ID'], row['NT2ID']])
        id_of = lambda seq: '%s-%s' % (family, seq)
        url = None

        pdb = row['PDBID']
        if row['Resolution'] == 'NaN':
            resolution = None
        else:
            resolution = float(row['Resolution'])

        if 'MODEL' in pdb:
            pdb = 'Modeled'
            resolution = None
            known = False
        elif 'CURATED' in pdb:
            pdb = pdb.split('_')[1]

        # We have to detect if we can get the coordinates for the given item.
        # We do this by trying to find the pdb fragment in the data directory,
        # if it is there we have it.
        case = 0
        if family[1].lower() == family[2].lower():
            if family[1] == family[2]:
                case = 0
            elif family[1] > family[2]:
                case = 1
            else:
                case = 2

        # seq_case = '%s-%s.pdb' % (first.upper(), case)
        # fragment = os.path.join('static', 'data', family, seq_case)
        simple_family = ''.join([char.upper() for char in family[1:]])
        fragment = FRAGMENT_URL.format(family[0] + simple_family,
                                       first.upper(), case)
        known = os.path.exists(fragment)

        if known:
            url = IMAGE_URL.format(family, first)

        data['items'][first] = {
            'id': id_of(first),
            'units': units,
            'pdb': pdb,
            'resolution': resolution,
            'group': row['LW 2002 subgroup'],
            'family': family,
            'count': int(row['Count']),
            'sequence': first,
            'coordinates_exist': known,
            'url': url
        }
        data['files'][first] = (row['FragmentFilename'], fragment)

        for key in names:
            if re.match('^[ACGUacgu]{2}$', key):
                data['pairs'].append({
                    'id': '%s-%s-%s' % (family, first, key),
                    'exists': (key != first) or known,
                    'idi': float(row[key]),
                    'items': [first, key],
                    'item_ids': [id_of(first), id_of(key)]
                })

    return data


def load_data(raw, family):
    reader = csv.reader(raw, delimiter=',')
    rows = [row for row in reader]
    header = rows.pop(0)
    header.insert(9, 'distance')

    sequences = filter(lambda seq: re.match('^[ACGU]{2}$', seq), header)
    if len(sequences) == len(set(sequences)):
        return generate_data(header, rows)

    f_index = header.index('Family')
    c_index = header.index('Base combination')

    offset = header.index(sequences[0])
    for index, row in enumerate(rows):
        family = row[f_index]
        sequence = row[c_index]
        if family[1] == family[2] or family[1].lower() != family[2].lower():
            name = sequence
        elif family[1] == family[1].upper():
            name = sequence[0] + sequence[1].lower()
        else:
            name = sequence[0].lower() + sequence[1]
        row[c_index] = name
        header[offset + index] = name

    return generate_data(header, rows)


def add_missing_items(data):
    known = [key.upper() for key in data['items'].keys()]
    item = data['items'][data['items'].keys()[0]]
    pdb = item['pdb']
    family = item['family']

    nts = ['A', 'C', 'G', 'U']
    possible = set([''.join(pair) for pair in zip(nts, nts)])
    missing = possible - set(known)
    for sequence in missing:
        data['items'][sequence] = {
            'id': '%s-%s' % (family, sequence),
            'units': [],
            'pdb': pdb,
            'resolution': None,
            'group': None,
            'family': family,
            'distance': None,
            'count': 0,
            'sequence': sequence,
            'coordinates_exist': False,
            'url': None
        }


def move_files(mapping, filename):
    base = os.path.dirname(filename)
    for name, (fragment, to) in mapping.items():
        path = os.path.join(base, fragment)
        shutil.copy(path, to)


def save(data):
    json.dump(data, sys.stdout)


def main(filename):
    name = os.path.basename(filename)[0:3]
    with open(filename, 'rb') as raw:
        data = load_data(raw, name)
    move_files(data.pop('files'), filename)
    add_missing_items(data)
    save(data)

if __name__ == '__main__':
    main(sys.argv[1])
